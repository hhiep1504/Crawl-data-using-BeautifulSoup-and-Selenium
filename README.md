# Crawl-data-using-BeautifulSoup-and-Selenium

This project demonstrates how to crawl real estate data from a website using BeautifulSoup and Selenium. Specifically, it scrapes data from the Century21 real estate listings for Dallas, TX.

## Prerequisites
- Python 3.x
- Jupyter Notebook

## Installation
1. Clone the repository: `git clone https://github.com/your-username/Crawl-data-using-BeautifulSoup-and-Selenium.git`
2. Navigate to the project directory: `cd Crawl-data-using-BeautifulSoup-and-Selenium`
3. Install the required packages: `pip install -r requirements.txt`

## Usage
1. Run each cell in the notebook to execute the code step by step.
2. The notebook will scrape real estate data from the Century21 website and save it to a CSV file named `dallas.csv`.

## Description
- The project uses BeautifulSoup for parsing HTML content and Selenium for automating web browser interaction.
- It navigates through the Century21 real estate listings for Dallas, TX, and extracts information such as listing type, price, bedrooms, bathrooms, area, address, and city.
- The data is stored in a CSV file for further analysis or visualization.

## Contributors
- Ha Hoang Hiep <hoanghiep4502@gmail.com>


## Acknowledgments
This project was developed as part of the coursework for the **Intro to Data Science** course at the SOICT, Hanoi University of Science and Technology (HUST).
