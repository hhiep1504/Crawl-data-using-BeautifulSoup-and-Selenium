{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoang\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'muasamcong.mpi.gov.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.century21.com/real-estate/dallas-tx/LCTXDALLAS/?sa=CTXADDISON%2CCTXBALCHSPRINGS%2CCTXCARROLLTON%2CCTXCOPPELL%2CCTXDESOTO%2CCTXDUNCANVILLE%2CCTXGARLAND%2CCTXGRANDPRAIRIE%2CCTXHUTCHINS%2CCTXIRVING%2CCTXLANCASTER%2CCTXMESQUITE%2CCTXRICHARDSON%2CCTXSACHSE&o=price-desc&sn=5&sk=Y&pt=1%2C2%2C3%2C7'\n",
    "#58 pages\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scrolling: 100%|██████████| 10/10 [00:50<00:00,  5.06s/iteration]\n",
      "Pages:   0%|          | 0/1 [00:00<?, ?page/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hoang\\Documents\\DS-AI\\Data Science\\real_estate_crawling\\real_estate_crawler.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m total_pages \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# Change this to the actual total number of pages\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mfor\u001b[39;00m page_number \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, total_pages \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPages\u001b[39m\u001b[39m\"\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpage\u001b[39m\u001b[39m\"\u001b[39m, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     \u001b[39m# Extract data from the current page\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     data_list \u001b[39m=\u001b[39m extract_data_from_page()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     total_data_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39m# Write data to CSV\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\hoang\\Documents\\DS-AI\\Data Science\\real_estate_crawling\\real_estate_crawler.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m city \u001b[39m=\u001b[39m city_elem\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip() \u001b[39mif\u001b[39;00m city_elem \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mN/A\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Click on the property card\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m card\u001b[39m.\u001b[39;49mclick()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)  \u001b[39m# Wait for the card to open\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hoang/Documents/DS-AI/Data%20Science/real_estate_crawling/real_estate_crawler.ipynb#W3sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m# Wait for the \"pdp-open\" class to appear\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "edge_driver_path = 'C:\\\\Users\\\\hoang\\\\Documents\\\\DS-AI\\\\Data Science\\\\real_estate_crawling\\\\msedgedriver.exe'\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + edge_driver_path\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "# Function to scroll down \n",
    "def scroll_into_view(element):\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "\n",
    "# Function to click the \"Next Page\" button\n",
    "def click_next_page():\n",
    "    try:\n",
    "        next_page_button = driver.find_element(By.ID, 'pagination-next')\n",
    "        scroll_into_view(next_page_button)\n",
    "        next_page_button.click()\n",
    "        time.sleep(10)  # Wait for the page to load\n",
    "    except NoSuchElementException:\n",
    "        print(\"Next page button not found.\")\n",
    "\n",
    "# Function to switch to grid view\n",
    "def switch_to_grid_view():\n",
    "    try:\n",
    "        grid_view_button = driver.find_element(By.ID, 'gallery-view-button')\n",
    "        grid_view_button.click()\n",
    "        time.sleep(2)  # Wait for the page to update\n",
    "    except NoSuchElementException:\n",
    "        print(\"Grid view button not found.\")\n",
    "# Set a delay to wait for the content to load\n",
    "scroll_delay = 5\n",
    "\n",
    "# Number of times to scroll down\n",
    "scroll_count = 10  # can be adjusted\n",
    "switch_to_grid_view() # depends on the website \n",
    "# Scroll down in a loop\n",
    "for _ in tqdm(range(scroll_count), desc=\"Scrolling\", unit=\"iteration\", position=0):\n",
    "    # Get the last property card element\n",
    "    last_card = driver.find_elements(By.CLASS_NAME, 'property-card-primary-info')[-1]\n",
    "    # Scroll to the last property card\n",
    "    scroll_into_view(last_card)\n",
    "    time.sleep(scroll_delay)\n",
    "\n",
    "\n",
    "# Function to extract data from the current page\n",
    "def extract_data_from_page():\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    property_cards = soup.find_all('div', class_='property-card-primary-info')\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for card in property_cards:\n",
    "        listing_type = card.find('div', class_='pdp-listing-type').text.strip()\n",
    "        price = card.find('a', class_='listing-price').text.strip()\n",
    "        bedrooms_elem = card.find('div', class_='property-beds')\n",
    "        bedrooms = bedrooms_elem.strong.text.strip() if bedrooms_elem else \"N/A\"\n",
    "        bathrooms_elem = card.find('div', class_='property-baths')\n",
    "        bathrooms = bathrooms_elem.strong.text.strip() if bathrooms_elem else \"N/A\"\n",
    "        area_elem = card.find('div', class_='property-sqft')\n",
    "        area = area_elem.strong.text.strip() if area_elem else \"N/A\"\n",
    "        address_elem = card.find('div', class_='property-address')\n",
    "        city_elem = card.find('div', class_='property-city')\n",
    "        address = address_elem.text.strip() if address_elem else \"N/A\"\n",
    "        city = city_elem.text.strip() if city_elem else \"N/A\"\n",
    "        # Click on the property card\n",
    "        card.click()\n",
    "        time.sleep(2)  # Wait for the card to open\n",
    "\n",
    "        # Wait for the \"pdp-open\" class to appear\n",
    "        pdp_open_elem = None\n",
    "        while pdp_open_elem is None:\n",
    "            try:\n",
    "                pdp_open_elem = driver.find_element(By.CLASS_NAME, 'pdp-open')\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "        pdp_open = pdp_open_elem.text.strip()\n",
    "\n",
    "        data_list.append([listing_type, price, bedrooms, bathrooms, area, address, city, pdp_open])\n",
    "\n",
    "    return data_list\n",
    "\n",
    "# Set a delay to wait for the content to load\n",
    "scroll_delay = 5\n",
    "\n",
    "# Switch to grid view\n",
    "switch_to_grid_view()\n",
    "total_data_count = 0\n",
    "# Iterate through all pages\n",
    "total_pages = 1  # Change this to the actual total number of pages\n",
    "for page_number in tqdm(range(1, total_pages + 1), desc=\"Pages\", unit=\"page\", position=0):\n",
    "    # Extract data from the current page\n",
    "    data_list = extract_data_from_page()\n",
    "    total_data_count += len(data_list)\n",
    "    # Write data to CSV\n",
    "    with open('tét.csv', 'a', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        # If it's the first page, write the header\n",
    "        if page_number == 1:\n",
    "            csv_writer.writerow(['Type', 'Price', 'Bedrooms', 'Bathrooms', 'Area', 'Address', 'City'])\n",
    "        csv_writer.writerows(data_list)\n",
    "\n",
    "    # Scroll down\n",
    "    last_card = driver.find_elements(By.CLASS_NAME, 'property-card-primary-info')[-1]\n",
    "    scroll_into_view(last_card)\n",
    "    time.sleep(scroll_delay)\n",
    "print(\"Total Data Points:\", total_data_count)\n",
    "# Quit the driver after scraping all pages\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scrolling: 100%|██████████| 10/10 [00:55<00:00,  5.57s/iteration]\n",
      "Pages: 100%|██████████| 58/58 [05:24<00:00,  5.59s/page]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Points: 5800\n"
     ]
    }
   ],
   "source": [
    "edge_driver_path = 'C:\\\\Users\\\\hoang\\\\Documents\\\\DS-AI\\\\Data Science\\\\real_estate_crawling\\\\msedgedriver.exe'\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + edge_driver_path\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "# Function to scroll down \n",
    "def scroll_into_view(element):\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "\n",
    "# Function to click the \"Next Page\" button\n",
    "def click_next_page():\n",
    "    try:\n",
    "        next_page_button = driver.find_element(By.ID, 'pagination-next')\n",
    "        scroll_into_view(next_page_button)\n",
    "        next_page_button.click()\n",
    "        time.sleep(10)  # Wait for the page to load\n",
    "    except NoSuchElementException:\n",
    "        print(\"Next page button not found.\")\n",
    "\n",
    "# Function to switch to grid view\n",
    "def switch_to_grid_view():\n",
    "    try:\n",
    "        grid_view_button = driver.find_element(By.ID, 'gallery-view-button')\n",
    "        grid_view_button.click()\n",
    "        time.sleep(2)  # Wait for the page to update\n",
    "    except NoSuchElementException:\n",
    "        print(\"Grid view button not found.\")\n",
    "# Set a delay to wait for the content to load\n",
    "scroll_delay = 5\n",
    "\n",
    "# Number of times to scroll down\n",
    "scroll_count = 10  # can be adjusted\n",
    "switch_to_grid_view() # depends on the website \n",
    "# Scroll down in a loop\n",
    "for _ in tqdm(range(scroll_count), desc=\"Scrolling\", unit=\"iteration\", position=0):\n",
    "    # Get the last property card element\n",
    "    last_card = driver.find_elements(By.CLASS_NAME, 'property-card-primary-info')[-1]\n",
    "    # Scroll to the last property card\n",
    "    scroll_into_view(last_card)\n",
    "    time.sleep(scroll_delay)\n",
    "\n",
    "\n",
    "# Function to extract data from the current page\n",
    "def extract_data_from_page():\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    property_cards = soup.find_all('div', class_='property-card-primary-info')\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for card in property_cards:\n",
    "        listing_type = card.find('div', class_='pdp-listing-type').text.strip()\n",
    "        price = card.find('a', class_='listing-price').text.strip()\n",
    "        bedrooms_elem = card.find('div', class_='property-beds')\n",
    "        bedrooms = bedrooms_elem.strong.text.strip() if bedrooms_elem else \"N/A\"\n",
    "        bathrooms_elem = card.find('div', class_='property-baths')\n",
    "        bathrooms = bathrooms_elem.strong.text.strip() if bathrooms_elem else \"N/A\"\n",
    "        area_elem = card.find('div', class_='property-sqft')\n",
    "        area = area_elem.strong.text.strip() if area_elem else \"N/A\"\n",
    "        address_elem = card.find('div', class_='property-address')\n",
    "        city_elem = card.find('div', class_='property-city')\n",
    "        address = address_elem.text.strip() if address_elem else \"N/A\"\n",
    "        city = city_elem.text.strip() if city_elem else \"N/A\"\n",
    "\n",
    "        data_list.append([listing_type, price, bedrooms, bathrooms, area, address, city])\n",
    "\n",
    "    return data_list\n",
    "\n",
    "# Set a delay to wait for the content to load\n",
    "scroll_delay = 5\n",
    "\n",
    "# Switch to grid view\n",
    "switch_to_grid_view()\n",
    "total_data_count = 0\n",
    "# Iterate through all pages\n",
    "total_pages = 58  # Change this to the actual total number of pages\n",
    "for page_number in tqdm(range(1, total_pages + 1), desc=\"Pages\", unit=\"page\", position=0):\n",
    "    # Extract data from the current page\n",
    "    data_list = extract_data_from_page()\n",
    "    total_data_count += len(data_list)\n",
    "    # Write data to CSV\n",
    "    with open('dallas.csv', 'a', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        # If it's the first page, write the header\n",
    "        if page_number == 1:\n",
    "            csv_writer.writerow(['Type', 'Price', 'Bedrooms', 'Bathrooms', 'Area', 'Address', 'City'])\n",
    "        csv_writer.writerows(data_list)\n",
    "\n",
    "    # Scroll down\n",
    "    last_card = driver.find_elements(By.CLASS_NAME, 'property-card-primary-info')[-1]\n",
    "    scroll_into_view(last_card)\n",
    "    time.sleep(scroll_delay)\n",
    "print(\"Total Data Points:\", total_data_count)\n",
    "# Quit the driver after scraping all pages\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
